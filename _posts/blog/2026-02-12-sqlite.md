---
layout: post
title: building sqlite with a small swarm
date: 2026-02-12
categories: machine_learning
---

## tl;dr

I tasked Claude, Codex, and Gemini to build a [SQLite-like engine](https://github.com/kiankyars/sqlite) in Rust.

- **18,849** lines of code
- parser, planner, volcano executor, pager, b+trees, wal, recovery, joins, aggregates, indexing, transaction semantics, grouped aggregates, and stats-aware planning all implemented
- 282 unit tests, all passing

## background

Treat software engineering like distributed systems, and force coordination with: git, lock files, tests, and merge discipline.

## setup

1. A remote the agents could continuously pull/push: `git@github.com:kiankyars/sqlite.git`
2. A launcher that first runs a bootstrap agent, then starts worker loops in detached `screen` sessions
3. Per-agent clones workspaces (`workspace-<id>`) with logs
4. The following harness:

- `AGENT_PROMPT.md`       // main agent task prompt
- `BOOTSTRAP_PROMPT.md`   // bootstrap (initialization) prompt
- `COALESCE_PROMPT.md`    // deduplication prompt for coalescer agent
- `launch_agents.sh`      // launches all agents and sets up isolated workspaces
- `agent_loop.sh`         // per-agent loop/worker script
- `restart_agents.sh`     // restarts agents
- `coalesce.sh`           // invokes the coalescing script

## workflow

1. **bootstrap phase**: one Claude run generates baseline docs, crate skeleton, and test harness.
    ```├── Cargo.toml         // crate manifest
    ├── DESIGN.md          // architecture design notes
    ├── PROGRESS.md        // test & build progress
    ├── README.md          // project overview
    ├── agent_logs         // per-agent log files
    ├── crates             // workspace subcrates
    ├── current_tasks      // lock files
    ├── notes              // inter-agent notes
    ├── target             // build artifacts
    └── test.sh            // test harness script```
2. **worker phase**: six workers loop forever (`2x Claude`, `2x Codex`, `2x Gemini`).

the loop is simple:

1. each agent pulls latest main
2. claims one scoped task
3. implements + tests against sqlite3 as oracle
4. updates shared progress/notes
5. push

## analysis

### coordination tax

- **84 / 154 commits (54.5%)** were lock/claim/stale-lock/release coordination
- demonstrates parallel-agent throughput depends heavily on lock hygiene and stale-lock cleanup discipline

### what helped most

Two things looked decisive:

- **oracle-style validation + high test cadence** (`cargo test ...` and `./test.sh --fast`/full runs captured in `PROGRESS.md`)
- **strong module boundaries** (`parser -> planner -> executor <-> storage`) so agents could work on orthogonal slices with fewer merge collisions

### redundancy

I implemented a coalescer with gemini to clean duplication/drift, since that is the largest problem with parallel agents. However, it only ran once at the end of the project, so it was never actually used during the run itself. I have a cron job which runs it daily, but gemini couldn't complete the entire de-deuplication when I ran it during the expirement itself, which is to say it stopped mid-way through.

### takeaways

- parallelism is great, but only with strict task boundaries.
- shared state docs (PROGRESS.md, design notes) are part of the runtime, not “documentation.”
- tests are the anti-entropy force.
- give agents a narrow interface, a common truth source, and fast feedback, and you get compounding throughput on real systems code.

## replication

To replicate this setup:

```bash
git clone git@github.com:kiankyars/parallel-ralph.git
mv parallel-ralph/sqlite .
chmod 700 sqlite/*.sh
./sqlite/launch_agents.sh
```

restart agents:

```bash
./sqlite/restart_agents.sh claude/codex/gemini
```

coalesce agent:

```bash
./sqlite/coalesce.sh
```

Assumes you have the relevant CLIs installed (`claude`, `codex`, `gemini`), plus `screen`, `git`, Rust toolchain, and `sqlite3`.

## limitations

- The documentation in the repo became enormous, `PROGRESS.md` became 490 lines and look at the sheer amount of [notes](https://github.com/kiankyars/sqlite/tree/main/notes); all this to say that the coalesce agent must be run as often as the other agents
- There isn't a great way to record token usage since each platform uses a different format, so I don't have a grasp on which agent pulled the most weight

## future work

- Track "substantive run rate", since many are rate-limited/nothing happened.
- Only Claude adds itself as a co-author to each commit and I did not do that for Codex and Gemini, so I need to add a commit message for Gemini and Codex
- Adding more strict observability because probably a lot of errors were due to the rate limit being hit mid work and then just not being able to like put then essentially at that point there was like only half finished work pushed.

## inspiration

- https://cursor.com/blog/scaling-agents
- https://www.anthropic.com/engineering/building-c-compiler

## appendix

### engine scope

- SQL parser/tokenizer/AST
- Planner with physical access-path selection (`TableScan`, `IndexEq`, `IndexRange`, `IndexOr`, `IndexAnd`, composite prefix/range)
- Volcano-style executor
- Pager with buffer pool + LRU + dirty tracking
- B+tree tables and secondary indexes (single + multi-column, including `UNIQUE`)
- DML/DDL: `CREATE TABLE`, `INSERT`, `SELECT`, `UPDATE`, `DELETE`, `DROP TABLE`, `DROP INDEX`
- Query features: `ORDER BY`, `LIMIT/OFFSET`, aggregates, `GROUP BY`, `HAVING`
- Join support: `INNER`, `CROSS`, `LEFT`, `RIGHT`, `FULL OUTER`
- WAL + commit/checkpoint/recovery
- SQL transaction control: `BEGIN` / `COMMIT` / `ROLLBACK`
- Scalar SQL functions and corrected LIKE semantics

### milestone commits

- **Foundation**
  - Bootstrap workspace, docs, harness (`16879bd`)
  - Tokenizer, SQL parser, AST (`15586d7`)
  - Pager and B+tree foundations/baseline (`3f8b2a3`, `8698bd8`)
- **Core SQL path**
  - End-to-end CRUD operations and secondary indexes (`9070529`, `58bb7b1`, `39d5147`)
  - Volcano-style executor (`aedda27`)
- **Durability**
  - WAL write path and commit (`b48518c`)
  - Checkpoint and recovery (`6137ec0`)
  - Transaction SQL (`342c147`)
  - Dirty-eviction transactional correctness (`7805ee6`)
- **Planner and Executor Growth**
  - Physical access path selection, range/OR/AND/multi-column/stats planner evolution (`aa24fb3`, `0b225c8`, `2b81d85`, `c60e580`, `0da32f2`, `8b0b5d7`)
  - Index equality/range (`600ab8f`, `aa24fb3`)
  - Multi-column equality, prefix, and range (`b147f1a`, `5e75b46`)
  - Cost heuristics, stats model, persisted stats (`c099b7c`, `c60e580`, `0da32f2`, `8b0b5d7`, `e96ad80`)
- **SQL Semantics**
  - JOIN family and grouped join semantics, including full join family and grouped aggregates (`02805ef`, `bfb1a49`, `3439033`, `2ad8d61`, `fafb387`, `8d965d5`)
  - Scalar SQL functions and join index probes (`85fbd7a`, `b9a39d1`)
  - LIKE semantics correctness fix (`ac59ad5`)
- **Coalesce/Cleanup**
  - Coalesce cleanup and deduplication (`1a14838`)

### code size snapshot

- Counted files (`.rs` + `.sh`): **15**
- Rust: **14 files / 18,650 lines**
- Shell: **1 file / 199 lines**
- Approx. non-blank, non-comment lines: **16,294** (Rust ~16,155 + Shell ~139)
- 154 commits between **2026-02-10** and **2026-02-12**

### usage

Gemini does not offer a way to monitor usage with their CLI. It's also not on a weekly usage basis, but rather a 24-hour usage basis. For codex, I used 100% of the Pro Plan weekly usage, which is currently on a 2x promotion. I used 70% of the Claude Pro weekly usage.

- codex
    - ![](/imgs/2026-02-12-sqlite/sqlite1.png)
- claude
    - ![](/imgs/2026-02-12-sqlite/sqlite2.png)
    - ![](/imgs/2026-02-12-sqlite/sqlite3.png)
    - ![](/imgs/2026-02-12-sqlite/sqlite4.png)

### disclaimer

- codex wrote the first draft for this post

## citation

```bibtex
@misc{kyars2026sqlite,
  author = {Kian Kyars},
  title = {Building SQLite With a Small Swarm},
  year = {2026},
  month = feb,
  day = {12},
  howpublished = {\url{https://kiankyars.github.io/machine_learning/2026/02/16/sqlite.html}},
  note = {Blog post}
}
```
