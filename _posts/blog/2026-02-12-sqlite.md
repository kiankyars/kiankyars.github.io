---
layout: post
title: Building SQLite With a Small Swarm
date: 2026-02-12
categories: machine_learning
---

## TL;DR

I tasked Claude, Codex, and Gemini to build a [SQLite-like engine](https://github.com/kiankyars/sqlite) in Rust from scratch.

- 154 commits between **2026-02-10** and **2026-02-12**
- parser, planner, volcano executor, pager, b+trees, wal, recovery, joins, aggregates, indexing, transaction semantics, grouped aggregates, and stats-aware planning all implemented
- unit tests grew from 11 to 282, all passing

## Background

Treat software engineering like distributed systems, and force coordination with: git, lock files, tests, and merge discipline.

## Setup

1. A remote the agents could continuously pull/push: `git@github.com:kiankyars/sqlite.git`
2. A launcher that first runs a bootstrap agent, then starts worker loops in detached `screen` sessions
3. Per-agent clones workspaces (`workspace-<id>`) with logs
4. The following harness:

- `AGENT_PROMPT.md`
- `BOOTSTRAP_PROMPT.md`
- `COALESCE_PROMPT.md`
- `launch_agents.sh`
- `agent_loop.sh`
- `restart_agents.sh`
- `coalesce.sh`

## Workflow

1. **Bootstrap phase**: one Claude run generates baseline docs, crate skeleton, and test harness.
2. **Worker phase**: six workers loop forever (`2x Claude`, `2x Codex`, `2x Gemini`) with pull/rebase, prompt execution, and logging.

the loop is simple:

1. each agent pulls latest main
2. claims one scoped task
3. implements + tests against sqlite3 as oracle
4. updates shared progress/notes
5. pushes back
6. a coalescer pass cleans duplication/drift

Coordination primitives in the repo were the same pattern as regex:

- `current_tasks/` for lock files
- `notes/` for handoffs
- `PROGRESS.md` for shared status + test receipts

## Analysis

### Where the real work happened

Most implementation velocity came from a compact set of milestone commits:

- bootstrap workspace/docs/harness (`16879bd`)
- tokenizer/parser/AST (`15586d7`)
- pager + B+tree foundations (`3f8b2a3`, `8698bd8`)
- end-to-end CRUD + secondary indexes (`9070529`, `58bb7b1`, `39d5147`)
- WAL + recovery + transaction SQL (`b48518c`, `6137ec0`, `342c147`)
- planner/executor evolution (range/or/and/multi-column/stats) (`aa24fb3`, `0b225c8`, `2b81d85`, `c60e580`, `0da32f2`, `8b0b5d7`)
- JOIN family and grouped join semantics (`02805ef`, `bfb1a49`, `3439033`, `2ad8d61`, `fafb387`)
- scalar SQL functions + join index probes (`85fbd7a`, `b9a39d1`)
- coalesce cleanup (`1a14838`)

## Deep-dive: commit archaeology

Milestone slices from commit history:

- Foundation:
  - bootstrap/docs/harness (`16879bd`)
  - parser/tokenizer/AST (`15586d7`)
  - pager + B+tree baseline (`3f8b2a3`, `8698bd8`)
- Core SQL path:
  - CRUD + indexing (`58bb7b1`, `39d5147`)
  - volcano executor (`aedda27`)
- Durability:
  - WAL write path + commit (`b48518c`)
  - checkpoint + recovery (`6137ec0`)
  - transaction SQL (`342c147`)
  - dirty-eviction transactional correctness (`7805ee6`)
- Planner growth:
  - index equality/range (`600ab8f`, `aa24fb3`)
  - OR union + AND intersection (`0b225c8`, `2b81d85`)
  - multi-column equality/prefix/range (`b147f1a`, `5e75b46`)
  - cost heuristics + stats model + persisted stats (`c099b7c`, `c60e580`, `0da32f2`, `8b0b5d7`, `e96ad80`)
- SQL semantics:
  - grouped aggregates (`8d965d5`, `fafb387`)
  - full join family (`02805ef`, `bfb1a49`, `3439033`, `2ad8d61`)
  - scalar SQL functions (`85fbd7a`)
  - LIKE correctness fix (`ac59ad5`)
  - join index-probe optimization (`b9a39d1`)

### Session count is not commit count (again)

Local log counts:

- Total logged sessions: **5,859**
- Claude loop logs: **5,767** (`agent_1` + `agent_2`)
- Codex loop logs: **53** (`agent_3`)
- Gemini loop logs: **36** (`agent_5` + `agent_6`)
- Bootstrap/coalesce logs: **3**

But almost all Claude logs were tiny limit messages:

- **5,765** logs were <=120 bytes and contained variants of `You've hit your limit ...`
- only **2** Claude logs were substantive (and both corresponded to real feature drops)

Gemini workers did not contribute implementation here because the binary was unavailable in-loop (`bash: gemini: command not found`).

### Coordination overhead was real

From commit subjects in `workspace-1`, about **83/154** commits were lock/claim/release/stale-lock coordination commits.

That overhead was acceptable for keeping the queue moving, but it confirms that parallel-agent throughput depends heavily on lock hygiene and stale-lock cleanup discipline.

## Deep-dive: coordination tax

From subject-line classification in `workspace-1`:

- **84 / 154 commits (54.5%)** were lock/claim/stale-lock/release coordination
- high coordination overhead, but low catastrophic merge breakage
- stale-lock cleanup was mandatory to keep queue progress

Takeaway: lock hygiene is not optional in parallel-agent repos; it is the control plane.

### What helped most

Two things looked decisive:

- **oracle-style validation + high test cadence** (`cargo test ...` and `./test.sh --fast`/full runs captured in `PROGRESS.md`)
- **strong module boundaries** (`parser -> planner -> executor <-> storage`) so agents could work on orthogonal slices with fewer merge collisions

## Replication

To replicate this setup:

```bash
git clone git@github.com:kiankyars/parallel-ralph.git
mv parallel-ralph/sqlite .
chmod 700 sqlite/*.sh
./sqlite/launch_agents.sh
```

Optional maintenance runs:

```bash
./sqlite/restart_agents.sh claude
./sqlite/restart_agents.sh codex
./sqlite/coalesce.sh
```

Assumes you have the relevant CLIs installed (`claude`, `codex`, optionally `gemini`), plus `screen`, `git`, Rust toolchain, and `sqlite3`.
a few takeaways:

- parallelism is great, but only with strict task boundaries.
- shared state docs (PROGRESS.md, design notes) are part of the runtime, not “documentation.”
- heterogeneous agents are useful: different models fail differently, which is exactly what you want in
ensemble systems.
- tests are the social contract. without them, multi-agent coding collapses into chaos quickly.
## Limitations

- The documentation in the repo became enormous.
- Adding more strict observability because probably a lot of errors were due to the rate limit being hit mid work and then just not being able to like put then essentially at that point there was like only half finished work pushed.
- Only Claude adds itself as a co-author to each commit and I did not do that for Codex and Gemini, so I need to add a commit message for Gemini and Codex
- There isn't a great way to record token usage since each platform uses a different format



what’s interesting is not that this works once. it’s that it keeps working repeatedly. the repo now has
broad SQL surface area, storage internals, and a long tail of planner/index optimizations, with high
automated test coverage and frequent full-workspace green runs.

the meta-lesson: “agentic coding” is less about magic autonomy and more about orchestration design. give
agents a narrow interface, a common truth source, and fast feedback, and you get compounding throughput on
real systems code.

## Future Work

Near-term engine work from the current backlog/recommendations:

- extend join index probes to `ON` conjunctions and multi-column join keys
- finish overflow-page implementation
- continue planner/statistics refinement for composite predicates

Process-side, I want to add stronger model-specific health checks before launch (to catch missing binaries early) and automate stale-lock cleanup with explicit TTL policy.
3. Track "substantive run rate" explicitly, not just run count.
## Inspiration

- https://cursor.com/blog/scaling-agents
- https://www.anthropic.com/engineering/building-c-compiler

## Appendix

### Code size snapshot

- Counted files (`.rs` + `.sh`): **15**
- Total lines: **18,849**
- Rust: **14 files / 18,650 lines**
- Shell: **1 file / 199 lines**
- Approx. non-blank, non-comment lines: **16,294** (Rust ~16,155 + Shell ~139)

### Timeline and commits

- First commit date in history: **2026-02-10**
- Latest commit date in history: **2026-02-12**
- Total commits in `main`: **154**

### Session/log snapshot

- Total logs: **5,859**
- Tiny rate-limit-like Claude logs: **5,765**
- Substantive Claude logs: **2**
- Codex logs: **53**
- Gemini logs: **36** (all command-not-found in this run)
- Bootstrap/coalesce logs: **3**

### Usage

Gemini does not offer a way to monitor usage with their CLI. It's also not on a weekly usage basis, but rather a 24-hour usage basis. For codex, I used 100% of the Pro Plan weekly usage, which is currently on a 2x promotion. I used 70% of the Claude Pro weekly usage.

- codex
    - ![](/imgs/2026-02-12-sqlite/sqlite1.png)
- claude
    - ![](/imgs/2026-02-12-sqlite/sqlite2.png)
    - ![](/imgs/2026-02-12-sqlite/sqlite3.png)
    - ![](/imgs/2026-02-12-sqlite/sqlite4.png)

## What got built (engine scope)

Final implemented surface (from docs + progress + milestone commits):

- SQL parser/tokenizer/AST
- Planner with physical access-path selection (`TableScan`, `IndexEq`, `IndexRange`, `IndexOr`, `IndexAnd`, composite prefix/range)
- Volcano-style executor
- Pager with buffer pool + LRU + dirty tracking
- B+tree tables and secondary indexes (single + multi-column, including `UNIQUE`)
- DML/DDL: `CREATE TABLE`, `INSERT`, `SELECT`, `UPDATE`, `DELETE`, `DROP TABLE`, `DROP INDEX`
- Query features: `ORDER BY`, `LIMIT/OFFSET`, aggregates, `GROUP BY`, `HAVING`
- Join support: `INNER`, `CROSS`, `LEFT`, `RIGHT`, `FULL OUTER`
- WAL + commit/checkpoint/recovery
- SQL transaction control: `BEGIN` / `COMMIT` / `ROLLBACK`
- Scalar SQL functions and corrected LIKE semantics






## Deep-dive: storage/planner tradeoffs from notes

Some concrete engineering decisions that improved correctness:

- **Transactional dirty eviction**: evicted dirty pages are spilled to in-memory state, not written early to DB file; commit path flushes pool + spill atomically.
- **WAL startup recovery**: replay only committed frames, ignore checksum-invalid/uncommitted tails, then truncate WAL.
- **Planner prefix fanout stats**: persisted `prefix_distinct_counts` enabled better composite prefix/range cost estimation.
- **Text range seek encoding**: ordered text keys used overlap-based encoding to preserve monotonic ordering while reducing long-prefix collisions.
- **LIKE semantics**: moved from naive substring matching to SQL wildcard semantics (`%`, `_`, NULL propagation).




### Disclaimer

- I asked codex to write the blog draft

## Citation

```bibtex
@misc{kyars2026sqlite,
  author = {Kian Kyars},
  title = {Building SQLite With a Small Swarm},
  year = {2026},
  month = feb,
  day = {12},
  howpublished = {\url{https://kiankyars.github.io/machine_learning/2026/02/16/sqlite.html}},
  note = {Blog post}
}
```
